{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning"
      ],
      "metadata": {
        "id": "taAye12JD5he"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dK1Wxp6DxFm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning dataset 1"
      ],
      "metadata": {
        "id": "s1zfIDNtD-JF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"Access_and_Use_of_Telemedicine_During_COVID-19.csv\")\n",
        "columns_to_keep = [col for col in df1.columns if col not in {'Suppression', 'Significant 1', 'Significant 2'}]\n",
        "df1_filtered = df1[columns_to_keep]\n",
        "\n",
        "df1_filtered = df1_filtered[(df1_filtered['Group'] != 'Total') & (df1_filtered['Subgroup'] != 'Total') & (df1_filtered['Response'] != 'Total')]"
      ],
      "metadata": {
        "id": "Wh9bIEs1Er2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep = [col for col in df1_filtered.columns if col not in {'Suppression', 'Significant 1', 'Significant 2'}]\n",
        "\n",
        "df1_filtered = df1_filtered[columns_to_keep]\n",
        "\n",
        "df1_clean = df1_filtered\n",
        "df1_clean = df1_clean[df1_clean['Group'].isin({'Urbanization', 'Education', 'Race/Hispanic origin'})]\n",
        "\n",
        "df1_clean.loc[df1_clean['Group'] == 'Education', 'Subgroup'] =  df1[df1['Group'] == 'Education']['Subgroup'].replace({\n",
        "    'High school graduate or less': 'highschool or less',\n",
        "    'Some college': 'college',\n",
        "    \"Bachelor's degree or above\": 'bachelor or above'\n",
        "})\n",
        "\n",
        "df1_clean.loc[df1_clean['Group'] == 'Urbanization', 'Subgroup'] = df1[df1['Group'] == 'Urbanization']['Subgroup'].replace({\n",
        "    'Metropolitan': 'Urban',\n",
        "    'Non-Metropolitan': 'Rural'\n",
        "})"
      ],
      "metadata": {
        "id": "sZ0SgOkgE8gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_final = df1_clean\n",
        "\n",
        "total_sample_sizes = (\n",
        "    df1_clean[df1_clean['Response'] == 'Total']\n",
        "    .groupby(['Round', 'Indicator', 'Group', 'Subgroup'])['Sample Size']\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "\n",
        "total_sample_sizes = total_sample_sizes.rename(columns={'Sample Size': 'Total Sample Size'})\n",
        "\n",
        "# merge the total sample sizes back into the original df\n",
        "df1_clean = pd.merge(df1_clean, total_sample_sizes, on=['Round', 'Indicator', 'Group', 'Subgroup'], how='left')\n",
        "\n",
        "# calculate \"size\"\n",
        "df1_clean['size'] = (df1_clean['Percent'] * df1_clean['Total Sample Size']) / 100\n",
        "\n",
        "# drop the temporary column\n",
        "df1_clean.drop(columns=['Total Sample Size'], inplace=True)"
      ],
      "metadata": {
        "id": "hdYwPZwgD96x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_clean.rename(columns={\"Sample Size\": \"SampleSize\"}, inplace=True)\n",
        "df1_clean.rename(columns={\"Standard Error\": \"StandardError\"}, inplace=True)\n",
        "df1_clean.rename(columns={\"Group\": \"majorGroup\"}, inplace=True)\n",
        "df1_clean.rename(columns={\"Subgroup\": \"SubGroup\"}, inplace=True)\n",
        "df1_clean.rename(columns={\"size\": \"sizeValue\"}, inplace=True)\n",
        "\n",
        "df1_clean.replace({pd.NA: None, np.nan: None}, inplace=True)"
      ],
      "metadata": {
        "id": "hPatnPUkPEbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_final = df1_clean.pivot(\n",
        "    index=['Round', 'Indicator', 'majorGroup', 'SubGroup', 'SampleSize', 'sizeValue'],\n",
        "    columns='Response',\n",
        "    values=['Percent', 'StandardError']\n",
        ").reset_index()\n",
        "\n",
        "# Flatten the column MultiIndex\n",
        "df1_final.columns = [f\"{col[0]}_{col[1]}\" if col[1] else col[0] for col in df1_final.columns]\n",
        "\n",
        "# Create Race and Urbanization columns\n",
        "df1_final['Race'] = df1_final['SubGroup'].where(df1_final['majorGroup'] == 'Race/Hispanic origin')\n",
        "df1_final['Urbanization'] = df1_final['SubGroup'].where(df1_final['majorGroup'] == 'Urbanization')\n",
        "df1_final['Education'] = df1_final['SubGroup'].where(df1_final['majorGroup'] == 'Education')\n",
        "\n",
        "\n",
        "# Drop redundant columns\n",
        "df1_final.drop(['majorGroup', 'SubGroup'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "v0N9cc9LPFIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_colnames(text):\n",
        "  names = text.lower()\n",
        "  names = names.split(' ')\n",
        "  final_name = names[0]\n",
        "  for i in names[1:]:\n",
        "    final_name += '_'+i\n",
        "  return final_name\n",
        "\n",
        "df1_final.columns = list(map(clean_colnames, df1_final.columns))\n",
        "\n",
        "urbanization_mapping = {\n",
        "    \"Rural\": \"Rural\",\n",
        "    \"Urban\": \"Urban\",\n",
        "    np.nan: \"Unknown\"  # Map missing values to \"Unknown\"\n",
        "}\n",
        "\n",
        "race_mapping = {\n",
        "    \"Rural\": \"Rural\",\n",
        "    \"Urban\": \"Urban\",\n",
        "    np.nan: \"Other non-Hispanic\"  # Map missing values to \"Unknown\"\n",
        "}\n",
        "\n",
        "education_mapping = {\n",
        "    'bachelor or above':'bachelor or above',\n",
        "    'college':'college',\n",
        "    'highschool or less':'highschool or less',\n",
        "    np.nan: \"Unknown\"\n",
        "}\n",
        "df1_final[\"urbanization\"] = df1_final[\"urbanization\"].replace(urbanization_mapping)\n",
        "df1_final[\"race\"] = df1_final[\"race\"].map(race_mapping).fillna(df1_final[\"race\"])\n",
        "df1_final[\"education\"] = df1_final[\"education\"].map(education_mapping).fillna(df1_final[\"education\"])\n",
        "\n",
        "# drop useless rows\n",
        "df1_final = df1_final[\n",
        "    (df1_final['race'] != 'Other non-Hispanic') |\n",
        "    (df1_final['education'] != 'Unknown') |\n",
        "    (df1_final['urbanization'] != 'Unknown')\n",
        "]"
      ],
      "metadata": {
        "id": "l_GSrk7rTZBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning dataset 2"
      ],
      "metadata": {
        "id": "esH9GZw8FFRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"TMEDTREND_PUBLIC_241126.csv\")\n",
        "\n",
        "df2_filtered = df2[df2['Year'].between(2020, 2022)]\n",
        "df2_filtered = df2_filtered[(df2_filtered['Bene_Race_Desc'] != 'All') & (df2_filtered['Bene_RUCA_Desc'] != 'All')]"
      ],
      "metadata": {
        "id": "eXGNk7TLFYFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Aggregate the data by relevant columns and sum numerical columns\n",
        "df2_clean = (\n",
        "    df2_filtered.groupby(['Bene_Race_Desc', 'Bene_RUCA_Desc', 'Bene_Mdcd_Mdcr_Enrl_Stus'])\n",
        "    .agg({\n",
        "        'Total_Bene_TH_Elig': 'sum',\n",
        "        'Total_PartB_Enrl': 'sum',\n",
        "        'Total_Bene_Telehealth': 'sum',\n",
        "        'Pct_Telehealth': 'mean'  # Use mean for percentage columns\n",
        "    })\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "\n",
        "df2_final = df2_clean\n",
        "\n",
        "def col_replacer(x):\n",
        "  if x == 'Bene_Race_Desc': return 'Race'\n",
        "  elif x == 'Bene_RUCA_Desc': return 'Urbanization'\n",
        "  elif x == 'Bene_Mdcd_Mdcr_Enrl_Stus': return 'Enrollment_Status'\n",
        "  else: return x\n",
        "\n",
        "cols = list(df2_clean.columns)\n",
        "cols_transformed = list(map(col_replacer, cols))\n",
        "df2_final.columns = cols_transformed\n",
        "\n",
        "race_mapping = {\n",
        "    \"All\": \"Total\",\n",
        "    \"Non-Hispanic White\": \"White non-Hispanic\",\n",
        "    \"Black/African American\": \"Black non-Hispanic\",\n",
        "    \"Other/Unknown\": \"Other non-Hispanic\",\n",
        "    \"Hispanic\": \"Hispanic\"\n",
        "}\n",
        "\n",
        "urban_mapping = {\n",
        "    \"Urban\": \"Urban\",\n",
        "    \"Rural\": \"Rural\"\n",
        "}\n",
        "\n",
        "# Apply mappings, keeping unmatched values\n",
        "df2_final[\"Race\"] = df2_final[\"Race\"].map(race_mapping).fillna(df2_final[\"Race\"])\n",
        "df2_final[\"Urbanization\"] = df2_final[\"Urbanization\"].map(urban_mapping).fillna(df2_final[\"Urbanization\"])\n",
        "df2_final.replace({pd.NA: None, np.nan: None}, inplace=True)\n",
        "df2_final.columns = list(map(clean_colnames, df2_final.columns))"
      ],
      "metadata": {
        "id": "qHK_zp3YFIzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_final.to_csv('Access_and_telemedicine_use_COVID19_CLEAN.csv', index=False)\n",
        "df2_final.to_csv('TIMETREND_PUBLIC_CLEAN.csv', index=False)"
      ],
      "metadata": {
        "id": "kCQ9-JedRCsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SQL script generator\n"
      ],
      "metadata": {
        "id": "0LpekOxZcnoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('Access_and_telemedicine_use_COVID19_CLEAN.csv')\n",
        "df2 = pd.read_csv('TIMETREND_PUBLIC_CLEAN.csv')"
      ],
      "metadata": {
        "id": "V4xXbt1HhBB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quote(val):\n",
        "    if pd.isna(val):\n",
        "        return 'NULL'\n",
        "    safe_val = str(val).replace('&', 'and').replace(\"'\", \"''\")\n",
        "    return f\"'{safe_val}'\""
      ],
      "metadata": {
        "id": "5oH5ESTBZWTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_filename = \"teleHealthData.sql\"\n",
        "\n",
        "with open(sql_filename, \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "DROP TABLE telemedicineprovider PURGE;\n",
        "DROP TABLE beneficiarydata PURGE;\n",
        "\n",
        "-- Create table for BeneficiaryData data\n",
        "CREATE TABLE beneficiarydata (\n",
        "  race VARCHAR(255),\n",
        "  urbanization VARCHAR(255),\n",
        "  enrollment_status VARCHAR(255),\n",
        "  total_bene_th_elig FLOAT,\n",
        "  total_partb_enrl FLOAT,\n",
        "  total_bene_telehealth FLOAT,\n",
        "  pct_telehealth FLOAT,\n",
        "  PRIMARY KEY (\n",
        "    race, urbanization\n",
        "  )\n",
        ");\n",
        "\n",
        "-- Create table for TelemedicineProvider data\n",
        "CREATE TABLE telemedicineprovider (\n",
        "  round INT,\n",
        "  indicator VARCHAR(255),\n",
        "  race VARCHAR(255),\n",
        "  urbanization VARCHAR(255),\n",
        "  education VARCHAR(255),\n",
        "  samplesize FLOAT,\n",
        "  sizevalue FLOAT,\n",
        "  percent_do_not_know FLOAT,\n",
        "  percent_no FLOAT,\n",
        "  percent_no_telemedicine_available FLOAT,\n",
        "  percent_no_usual_place_of_care FLOAT,\n",
        "  percent_yes FLOAT,\n",
        "  standarderror_do_not_know FLOAT,\n",
        "  standarderror_no FLOAT,\n",
        "  standarderror_no_telemedicine_available FLOAT,\n",
        "  standarderror_no_usual_place_of_care FLOAT,\n",
        "  standarderror_yes FLOAT,\n",
        "  PRIMARY KEY (round, indicator, race, urbanization, education),\n",
        "  FOREIGN KEY (race, urbanization) REFERENCES beneficiarydata(race, urbanization));\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "    f.write(\"-- SQL Script for Bulk Insert into Oracle DB\\n\\n\")\n",
        "\n",
        "    # Insert statements for beneficiarydata\n",
        "    f.write(\"INSERT ALL\\n\")\n",
        "    for _, row in df2.iterrows():\n",
        "        f.write(\"    INTO beneficiarydata (race, urbanization, enrollment_status, total_bene_th_elig, total_partb_enrl, total_bene_telehealth, pct_telehealth)\\n\")\n",
        "        f.write(f\"    VALUES ({quote(row['race'])}, {quote(row['urbanization'])}, {quote(row['enrollment_status'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['total_bene_th_elig']) else float(row['total_bene_th_elig'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['total_partb_enrl']) else float(row['total_partb_enrl'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['total_bene_telehealth']) else float(row['total_bene_telehealth'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['pct_telehealth']) else float(row['pct_telehealth'])})\\n\")\n",
        "    f.write(\"SELECT 1 FROM DUAL;\\n\")\n",
        "\n",
        "    # Insert statements for telemedicineprovider\n",
        "    f.write(\"INSERT ALL\\n\")\n",
        "    for _, row in df1.iterrows():\n",
        "        f.write(\"    INTO telemedicineprovider (round, indicator, race, urbanization, education, samplesize, sizevalue,\\n\")\n",
        "        f.write(\"         percent_do_not_know, percent_no, percent_no_telemedicine_available, percent_no_usual_place_of_care, percent_yes,\\n\")\n",
        "        f.write(\"         standarderror_do_not_know, standarderror_no, standarderror_no_telemedicine_available, standarderror_no_usual_place_of_care, standarderror_yes)\\n\")\n",
        "        f.write(f\"    VALUES ({'NULL' if pd.isna(row['round']) else int(row['round'])}, \"\n",
        "                f\"{quote(row['indicator'])}, {quote(row['race'])}, {quote(row['urbanization'])}, {quote(row['education'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['samplesize']) else float(row['samplesize'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['sizevalue']) else float(row['sizevalue'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['percent_do_not_know']) else float(row['percent_do_not_know'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['percent_no']) else float(row['percent_no'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['percent_no_telemedicine_available']) else float(row['percent_no_telemedicine_available'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['percent_no_usual_place_of_care']) else float(row['percent_no_usual_place_of_care'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['percent_yes']) else float(row['percent_yes'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['standarderror_do_not_know']) else float(row['standarderror_do_not_know'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['standarderror_no']) else float(row['standarderror_no'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['standarderror_no_telemedicine_available']) else float(row['standarderror_no_telemedicine_available'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['standarderror_no_usual_place_of_care']) else float(row['standarderror_no_usual_place_of_care'])}, \"\n",
        "                f\"{'NULL' if pd.isna(row['standarderror_yes']) else float(row['standarderror_yes'])})\\n\")\n",
        "    f.write(\"SELECT 1 FROM DUAL;\\n\\n\")\n",
        "\n",
        "print(\"SQL script generated\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neOB8fVWZAwc",
        "outputId": "359feccd-d972-4edc-b354-7bad0451a203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SQL script generated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4On7XE5NMWf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}